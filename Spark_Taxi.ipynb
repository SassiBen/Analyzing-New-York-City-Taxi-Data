{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b15c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=========================================================================================\n",
    "Topic: Analyzing New York City Taxi Data\n",
    "Author: Benalouache Sassi\n",
    "Date: 23/10/2023\n",
    "=========================================================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "423749de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Dependencies\n",
    "# ==========================\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, rank, expr, unix_timestamp, udf, StringType, rand, broadcast\n",
    "from pyspark.sql.functions import sum as spark_sum\n",
    "from pyspark.sql.window import Window\n",
    "from shapely.geometry import Point, shape\n",
    "from pyspark.sql import functions as F\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "157f1dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "143475cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 1. Initialization and Data Loading\n",
    "# ==========================\n",
    "\n",
    "# Initialize a Spark session\n",
    "spark = SparkSession.builder.appName('TaxiDataAnalysis').getOrCreate()\n",
    "\n",
    "# Load the taxi ride data\n",
    "taxi_data = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv('./Taxi_Data/Sample NYC Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee1dc525",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02bc5941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- medallion: string (nullable = true)\n",
      " |-- hack_license: string (nullable = true)\n",
      " |-- vendor_id: string (nullable = true)\n",
      " |-- rate_code: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- pickup_datetime: string (nullable = true)\n",
      " |-- dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- pickup_longitude: double (nullable = true)\n",
      " |-- pickup_latitude: double (nullable = true)\n",
      " |-- dropoff_longitude: double (nullable = true)\n",
      " |-- dropoff_latitude: double (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+---------+---------+------------------+---------------+----------------+---------------+----------------+---------------+-----------------+----------------+\n",
      "|           medallion|        hack_license|vendor_id|rate_code|store_and_fwd_flag|pickup_datetime|dropoff_datetime|passenger_count|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|\n",
      "+--------------------+--------------------+---------+---------+------------------+---------------+----------------+---------------+----------------+---------------+-----------------+----------------+\n",
      "|89D227B655E5C82AE...|BA96DE419E711691B...|      CMT|        1|                 N| 01-01-13 15:11|  01-01-13 15:18|              4|      -73.978165|      40.757977|       -73.989838|       40.751171|\n",
      "|0BD7C8F5BA12B88E0...|9FD8F69F0804BDB55...|      CMT|        1|                 N|  06-01-13 0:18|   06-01-13 0:22|              1|      -74.006683|      40.731781|       -73.994499|        40.75066|\n",
      "|0BD7C8F5BA12B88E0...|9FD8F69F0804BDB55...|      CMT|        1|                 N| 05-01-13 18:49|  05-01-13 18:54|              1|      -74.004707|       40.73777|       -74.009834|       40.726002|\n",
      "|DFD2202EE08F7A8DC...|51EE87E3205C985EF...|      CMT|        1|                 N| 07-01-13 23:54|  07-01-13 23:58|              2|      -73.974602|      40.759945|       -73.984734|       40.759388|\n",
      "|DFD2202EE08F7A8DC...|51EE87E3205C985EF...|      CMT|        1|                 N| 07-01-13 23:25|  07-01-13 23:34|              1|       -73.97625|      40.748528|       -74.002586|       40.747868|\n",
      "|20D9ECB2CA0767CF7...|598CCE5B9C1918568...|      CMT|        1|                 N| 07-01-13 15:27|  07-01-13 15:38|              1|      -73.966743|      40.764252|       -73.983322|       40.743763|\n",
      "|496644932DF393260...|513189AD756FF14FE...|      CMT|        1|                 N| 08-01-13 11:01|  08-01-13 11:08|              1|      -73.995804|      40.743977|       -74.007416|       40.744343|\n",
      "|0B57B9633A2FECD3D...|CCD4367B417ED6634...|      CMT|        1|                 N| 07-01-13 12:39|  07-01-13 13:10|              3|      -73.989937|      40.756775|        -73.86525|        40.77063|\n",
      "|2C0E91FF20A856C89...|1DA2F6543A62B8ED9...|      CMT|        1|                 N| 07-01-13 18:15|  07-01-13 18:20|              1|      -73.980072|      40.743137|       -73.982712|       40.735336|\n",
      "|2D4B95E2FA7B2E851...|CD2F522EEE1FF5F5A...|      CMT|        1|                 N| 07-01-13 15:33|  07-01-13 15:49|              2|      -73.977936|      40.786983|       -73.952919|        40.80637|\n",
      "|E12F6AF991172EAC3...|06918214E951FA000...|      CMT|        1|                 N| 08-01-13 13:11|  08-01-13 13:19|              1|      -73.982452|      40.773167|       -73.964134|       40.773815|\n",
      "|E12F6AF991172EAC3...|06918214E951FA000...|      CMT|        1|                 N|  08-01-13 9:50|  08-01-13 10:02|              1|       -73.99556|      40.749294|       -73.988686|       40.759052|\n",
      "|78FFD9CD0CDA541F3...|E949C583ECF62C8F0...|      CMT|        1|                 N| 10-01-13 12:07|  10-01-13 12:17|              1|      -73.971497|      40.791321|       -73.964478|       40.775921|\n",
      "|237F49C3ECC11F502...|93C363DDF8ED9385D...|      CMT|        1|                 N|  07-01-13 7:35|   07-01-13 7:46|              1|       -73.98851|      40.774307|       -73.981094|       40.755325|\n",
      "|3349F919AA8AE5DC9...|7CE849FEF67514F08...|      CMT|        1|                 N| 10-01-13 15:42|  10-01-13 16:04|              1|      -73.994911|      40.723221|       -73.971558|       40.761612|\n",
      "|3349F919AA8AE5DC9...|7CE849FEF67514F08...|      CMT|        1|                 N| 10-01-13 14:27|  10-01-13 14:45|              1|      -74.010391|      40.708702|       -73.987846|       40.756104|\n",
      "|4C005EEBAA7BF26B8...|351BE7D984BE17DB2...|      CMT|        1|                 N| 07-01-13 22:09|  07-01-13 22:19|              1|      -73.973732|      40.756287|       -73.998413|       40.756832|\n",
      "|7D99C30FCE69B1A9D...|460C3F57DD9CB2265...|      CMT|        1|                 N| 07-01-13 17:18|  07-01-13 17:20|              1|      -73.968925|      40.767704|        -73.96199|       40.776566|\n",
      "|E6FBF80668FE0611A...|36773E80775F26CD1...|      CMT|        1|                 N|  07-01-13 6:08|   07-01-13 6:13|              1|       -73.96212|      40.769737|       -73.979561|        40.75539|\n",
      "|0C5296F3C8B16E702...|D2363240A9295EF57...|      CMT|        1|                 N| 07-01-13 22:25|  07-01-13 22:36|              1|      -73.989708|      40.756714|       -73.977615|       40.787575|\n",
      "+--------------------+--------------------+---------+---------+------------------+---------------+----------------+---------------+----------------+---------------+-----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Number of Rows: 99999\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# 2. Data Exploration\n",
    "# ==========================\n",
    "\n",
    "# Display the schema and the first few rows to understand the data\n",
    "taxi_data.printSchema()\n",
    "taxi_data.show()\n",
    "\n",
    "# Display the number of rows\n",
    "row_count = taxi_data.count()\n",
    "print(\"Number of Rows:\", row_count)\n",
    "old_row_count = row_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "239d825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7aa0f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list of the valid taxis: 10013\n",
      "+--------------------+--------------------+----------+\n",
      "|           medallion|        hack_license|ride_count|\n",
      "+--------------------+--------------------+----------+\n",
      "|B91CBA168CDFF2963...|02856AFC22881ABCA...|         3|\n",
      "|D27A0F1D7A560D03E...|03A2D28F831C5C3E5...|         8|\n",
      "|A47A97A6E57264A1C...|069B5562096AF7684...|         1|\n",
      "|204BAB16D3382C5A5...|0FBF11956EE14B253...|        12|\n",
      "|3CACE6A20EB462544...|130328475AD7427AF...|         1|\n",
      "|CD89A39EA4C16B62D...|138B0A7B7D3B898E4...|         1|\n",
      "|FB8C95542F2EA53BD...|13CD9D132F9DFE9BD...|         3|\n",
      "|0D5744C51DAABD952...|28A7C858D9231A3EC...|         2|\n",
      "|9DDC978C91239BCDB...|2E18539FA05E802C2...|         5|\n",
      "|299D366EE8BC7D8C3...|31195E1D3AA1EC26D...|        11|\n",
      "|7EE820827C3806BB6...|3183016714F5E253E...|        11|\n",
      "|97A12ACC40B7F500B...|428AE5AF18511D16B...|        29|\n",
      "|0797C43D0AB24B4F3...|42D2B75CA34A867A4...|         4|\n",
      "|99DC8B92B9DD3926C...|44D39A75B5BADD81E...|         5|\n",
      "|2D582E009BC6D0DC1...|49EE1E8ECFA1C6D35...|         3|\n",
      "|0DC4DDFEC71A53DBB...|4B6EFCBC110DB539E...|         1|\n",
      "|4F6E2CAB7448FC65F...|4CEC9B9F46ABAB3AD...|        25|\n",
      "|8E3396EF02DA37EF5...|588A002C06DD0B24F...|        16|\n",
      "|6A4EB13F46065C703...|669FA40A7222D4DC2...|        24|\n",
      "|DA1A4CB0E75444C73...|69996930170E51265...|        19|\n",
      "+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "The list of false taxis: 137\n",
      "+--------------------+--------------------+----------+\n",
      "|           medallion|        hack_license|ride_count|\n",
      "+--------------------+--------------------+----------+\n",
      "|7BB8A299FE111E116...|479C9DBFA8F1E2B5E...|         2|\n",
      "|93A078B503419FB36...|237667D91B174B58E...|         5|\n",
      "|C135A2D2BCFA21DD8...|C060D24F756C29621...|         7|\n",
      "|C1A48FC85303DE1EA...|0AEA08FFEF113163D...|         1|\n",
      "|541F30BF9781EC064...|F7CDEEB7A6AAA535A...|         1|\n",
      "|7C4213FD4F01493DB...|55CA3F571F4D3C358...|         1|\n",
      "|1D0FBDD8767815893...|0F76287C75E5B855B...|         1|\n",
      "|F5BB809E7858A669C...|6EAC42CCC7CB1DA39...|         3|\n",
      "|DC888C3925E3B3E09...|CF4E90FAC9A5A20D0...|         1|\n",
      "|78517F620884284B3...|D03BCD997D8CEE751...|         1|\n",
      "|41C9DE08D0989127D...|CC9C58E4E8E8E9FFE...|         1|\n",
      "|D225B988186CB582C...|FFEB80F39533ACF27...|         2|\n",
      "|8CE240F0796D072D5...|AB2084BD6809E4110...|         1|\n",
      "|4D9B12EA20D314D0A...|FC2F8A825A9638CAE...|         2|\n",
      "|2EFC4AADDD2B68E51...|768BDF3E57F35536F...|         2|\n",
      "|69ED9B170A650C304...|23A1E6B3FF2D80309...|         1|\n",
      "|6AA8189D8B4433761...|7A4ECA444C6D456E0...|         1|\n",
      "|BC5AB7D6ABFFD0FAB...|36BC7E595146CF2B6...|         3|\n",
      "|E3BE706403627C3D4...|4045C05F38C2E333B...|         1|\n",
      "|734144E544344E735...|C479DD0821712179A...|         3|\n",
      "+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Number of null rows: 0\n",
      "Rows with invalid passenger count: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 99773\n",
      "Total rows cleaned: 226\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# 3. Data Cleaning and Preprocessing\n",
    "# ==========================\n",
    "\n",
    "# Group by 'medallion' and 'hack_license' to count the number of rides for each taxi\n",
    "taxi_counts = taxi_data.groupBy(\"medallion\", \"hack_license\").agg(count(\"*\").alias(\"ride_count\"))\n",
    "\n",
    "# Extract unique taxis and their ride counts\n",
    "taxis = taxi_counts.select(\"medallion\", \"hack_license\", \"ride_count\").distinct()\n",
    "\n",
    "# Rank taxis by ride_count within each 'hack_license' group\n",
    "window_spec = Window.partitionBy(\"hack_license\").orderBy(col(\"ride_count\").desc())\n",
    "ranked_taxis = taxis.withColumn(\"rank\", rank().over(window_spec))\n",
    "\n",
    "# Retain only the top-ranked taxi for each 'hack_license' (the one with the highest ride_count)\n",
    "filtered_taxis = ranked_taxis.filter(\"rank == 1\").drop(\"rank\")\n",
    "\n",
    "# Display the valid taxis and their count\n",
    "print(\"The list of the valid taxis:\", filtered_taxis.count())\n",
    "filtered_taxis.show()\n",
    "\n",
    "# Extract taxis that have duplicate 'hack_license' values\n",
    "dupe_taxis = ranked_taxis.filter(\"rank > 1\").drop(\"rank\")\n",
    "print(\"The list of false taxis:\", dupe_taxis.count())\n",
    "dupe_taxis.show()\n",
    "\n",
    "# Compute the total number of rides associated with false taxis\n",
    "total_rides = dupe_taxis.agg(spark_sum(\"ride_count\").alias(\"total rides with false Taxi\"))\n",
    "\n",
    "# Identify unique combinations of 'medallion' and 'hack_license' among the false taxis\n",
    "unique_taxi_combinations = dupe_taxis.select(\"medallion\", \"hack_license\").distinct()\n",
    "\n",
    "# Use broadcasting for optimizing the join operation (assuming 'unique_taxi_combinations' is small)\n",
    "taxi_data = taxi_data.join(broadcast(unique_taxi_combinations), on=['medallion', 'hack_license'], how='left_anti')\n",
    "\n",
    "# Remove rows with missing values in essential columns\n",
    "initial_count = taxi_data.count()\n",
    "taxi_data = taxi_data.dropna(subset=[\"medallion\", \"hack_license\", \"pickup_datetime\", \"dropoff_datetime\", \"passenger_count\", \"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\"])\n",
    "print(\"Number of null rows:\", initial_count - taxi_data.count())\n",
    "\n",
    "# Filter out rows with invalid passenger counts\n",
    "initial_count = taxi_data.count()\n",
    "T = taxi_data.filter((col(\"passenger_count\") > 0))\n",
    "print(\"Rows with invalid passenger count:\", initial_count - T.count())\n",
    "\n",
    "# Drop unnecessary columns\n",
    "T = T.drop(\"medallion\", \"passenger_count\", \"vendor_id\", \"rate_code\", \"store_and_fwd_flag\")\n",
    "\n",
    "# Display the final row count and the total number of rows cleaned\n",
    "print(\"Number of Rows:\", T.count())\n",
    "print(\"Total rows cleaned:\", old_row_count - T.count())\n",
    "old_row_count_2 = T.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d39ff17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+----------------+----------------+---------------+-----------------+----------------+\n",
      "|        hack_license|pickup_datetime|dropoff_datetime|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|\n",
      "+--------------------+---------------+----------------+----------------+---------------+-----------------+----------------+\n",
      "|BA96DE419E711691B...| 01-01-13 15:11|  01-01-13 15:18|      -73.978165|      40.757977|       -73.989838|       40.751171|\n",
      "|9FD8F69F0804BDB55...|  06-01-13 0:18|   06-01-13 0:22|      -74.006683|      40.731781|       -73.994499|        40.75066|\n",
      "|9FD8F69F0804BDB55...| 05-01-13 18:49|  05-01-13 18:54|      -74.004707|       40.73777|       -74.009834|       40.726002|\n",
      "|51EE87E3205C985EF...| 07-01-13 23:54|  07-01-13 23:58|      -73.974602|      40.759945|       -73.984734|       40.759388|\n",
      "|51EE87E3205C985EF...| 07-01-13 23:25|  07-01-13 23:34|       -73.97625|      40.748528|       -74.002586|       40.747868|\n",
      "|598CCE5B9C1918568...| 07-01-13 15:27|  07-01-13 15:38|      -73.966743|      40.764252|       -73.983322|       40.743763|\n",
      "|513189AD756FF14FE...| 08-01-13 11:01|  08-01-13 11:08|      -73.995804|      40.743977|       -74.007416|       40.744343|\n",
      "|CCD4367B417ED6634...| 07-01-13 12:39|  07-01-13 13:10|      -73.989937|      40.756775|        -73.86525|        40.77063|\n",
      "|1DA2F6543A62B8ED9...| 07-01-13 18:15|  07-01-13 18:20|      -73.980072|      40.743137|       -73.982712|       40.735336|\n",
      "|CD2F522EEE1FF5F5A...| 07-01-13 15:33|  07-01-13 15:49|      -73.977936|      40.786983|       -73.952919|        40.80637|\n",
      "|06918214E951FA000...| 08-01-13 13:11|  08-01-13 13:19|      -73.982452|      40.773167|       -73.964134|       40.773815|\n",
      "|06918214E951FA000...|  08-01-13 9:50|  08-01-13 10:02|       -73.99556|      40.749294|       -73.988686|       40.759052|\n",
      "|E949C583ECF62C8F0...| 10-01-13 12:07|  10-01-13 12:17|      -73.971497|      40.791321|       -73.964478|       40.775921|\n",
      "|93C363DDF8ED9385D...|  07-01-13 7:35|   07-01-13 7:46|       -73.98851|      40.774307|       -73.981094|       40.755325|\n",
      "|7CE849FEF67514F08...| 10-01-13 15:42|  10-01-13 16:04|      -73.994911|      40.723221|       -73.971558|       40.761612|\n",
      "|7CE849FEF67514F08...| 10-01-13 14:27|  10-01-13 14:45|      -74.010391|      40.708702|       -73.987846|       40.756104|\n",
      "|351BE7D984BE17DB2...| 07-01-13 22:09|  07-01-13 22:19|      -73.973732|      40.756287|       -73.998413|       40.756832|\n",
      "|460C3F57DD9CB2265...| 07-01-13 17:18|  07-01-13 17:20|      -73.968925|      40.767704|        -73.96199|       40.776566|\n",
      "|36773E80775F26CD1...|  07-01-13 6:08|   07-01-13 6:13|       -73.96212|      40.769737|       -73.979561|        40.75539|\n",
      "|D2363240A9295EF57...| 07-01-13 22:25|  07-01-13 22:36|      -73.989708|      40.756714|       -73.977615|       40.787575|\n",
      "+--------------------+---------------+----------------+----------------+---------------+-----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unpersist the data to free up memory\n",
    "taxis.unpersist()\n",
    "ranked_taxis.unpersist()\n",
    "filtered_taxis.unpersist()\n",
    "dupe_taxis.unpersist()\n",
    "unique_taxi_combinations.unpersist()\n",
    "\n",
    "T.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c819d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03d0a894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 110:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+-----------------+--------+--------------+---------------+\n",
      "|        hack_license|pickup_timestamp|dropoff_timestamp|Duration|pickup_borough|dropoff_borough|\n",
      "+--------------------+----------------+-----------------+--------+--------------+---------------+\n",
      "|BA96DE419E711691B...|      1357053060|       1357053480|     7.0|     Manhattan|      Manhattan|\n",
      "|9FD8F69F0804BDB55...|      1357431480|       1357431720|     4.0|     Manhattan|      Manhattan|\n",
      "|9FD8F69F0804BDB55...|      1357411740|       1357412040|     5.0|     Manhattan|      Manhattan|\n",
      "|51EE87E3205C985EF...|      1357602840|       1357603080|     4.0|     Manhattan|      Manhattan|\n",
      "|51EE87E3205C985EF...|      1357601100|       1357601640|     9.0|     Manhattan|      Manhattan|\n",
      "|598CCE5B9C1918568...|      1357572420|       1357573080|    11.0|     Manhattan|      Manhattan|\n",
      "|513189AD756FF14FE...|      1357642860|       1357643280|     7.0|     Manhattan|      Manhattan|\n",
      "|CCD4367B417ED6634...|      1357562340|       1357564200|    31.0|     Manhattan|         Queens|\n",
      "|1DA2F6543A62B8ED9...|      1357582500|       1357582800|     5.0|     Manhattan|      Manhattan|\n",
      "|CD2F522EEE1FF5F5A...|      1357572780|       1357573740|    16.0|     Manhattan|      Manhattan|\n",
      "|06918214E951FA000...|      1357650660|       1357651140|     8.0|     Manhattan|      Manhattan|\n",
      "|06918214E951FA000...|      1357638600|       1357639320|    12.0|     Manhattan|      Manhattan|\n",
      "|E949C583ECF62C8F0...|      1357819620|       1357820220|    10.0|     Manhattan|      Manhattan|\n",
      "|93C363DDF8ED9385D...|      1357544100|       1357544760|    11.0|     Manhattan|      Manhattan|\n",
      "|7CE849FEF67514F08...|      1357832520|       1357833840|    22.0|     Manhattan|      Manhattan|\n",
      "|7CE849FEF67514F08...|      1357828020|       1357829100|    18.0|     Manhattan|      Manhattan|\n",
      "|351BE7D984BE17DB2...|      1357596540|       1357597140|    10.0|     Manhattan|      Manhattan|\n",
      "|460C3F57DD9CB2265...|      1357579080|       1357579200|     2.0|     Manhattan|      Manhattan|\n",
      "|36773E80775F26CD1...|      1357538880|       1357539180|     5.0|     Manhattan|      Manhattan|\n",
      "|D2363240A9295EF57...|      1357597500|       1357598160|    11.0|     Manhattan|      Manhattan|\n",
      "+--------------------+----------------+-----------------+--------+--------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):                                              \n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 186, in manager\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 74, in worker\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 642, in main\n",
      "    if read_int(infile) == SpecialLengths.END_OF_STREAM:\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 595, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# 4. Enrichment and Feature Engineering\n",
    "# ==========================\n",
    "\n",
    "# Time enrichment\n",
    "# UDF to compute timestamps\n",
    "def compute_timestamps(df):\n",
    "    df = df.withColumn(\"pickup_timestamp\", unix_timestamp(\"pickup_datetime\", \"dd-MM-yy H:mm\"))\n",
    "    df = df.withColumn(\"dropoff_timestamp\", unix_timestamp(\"dropoff_datetime\", \"dd-MM-yy H:mm\"))\n",
    "    return df\n",
    "\n",
    "# UDF to filter duration\n",
    "def filter_duration(df):\n",
    "    df = df.withColumn(\"Duration\", (col(\"dropoff_timestamp\") - col(\"pickup_timestamp\")) / 60)  # Duration in minutes\n",
    "    df = df.filter((col(\"Duration\") > 0) & (col(\"Duration\") < 240.0))\n",
    "    return df\n",
    "\n",
    "\n",
    "# Borough enrichment\n",
    "# UDF to read GeoJSON data\n",
    "def read_geojson_data(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        return file.read()\n",
    "    \n",
    "# UDF to get borough based on longitude and latitude\n",
    "def get_borough(longitude, latitude, sorted_polygons):\n",
    "    point = Point(longitude, latitude)\n",
    "    for feature in sorted_polygons:\n",
    "        polygon = shape(feature['geometry'])\n",
    "        if polygon.contains(point):\n",
    "            return feature['properties']['borough']\n",
    "    return None\n",
    "\n",
    "# UDF to enrich data with borough information\n",
    "def enrich_with_borough(df, sorted_polygons):\n",
    "    borough_udf = udf(lambda x, y: get_borough(x, y, sorted_polygons), StringType())\n",
    "    df = df.withColumn(\"pickup_borough\", borough_udf(df[\"pickup_longitude\"], df[\"pickup_latitude\"])) \\\n",
    "           .withColumn(\"dropoff_borough\", borough_udf(df[\"dropoff_longitude\"], df[\"dropoff_latitude\"]))\n",
    "    return df\n",
    "\n",
    "# UDF to clean data\n",
    "def clean_data(df):\n",
    "    df = df.dropna(subset=[\"Duration\", \"pickup_borough\", \"dropoff_borough\", \"pickup_timestamp\", \"dropoff_timestamp\"])\n",
    "    df = df.drop(\"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\", \"pickup_datetime\", \"dropoff_datetime\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# Load and parse GeoJSON data\n",
    "geojson_data = read_geojson_data(\"./Taxi_Data/nyc-boroughs.geojson\")\n",
    "geojson = json.loads(geojson_data)\n",
    "sorted_polygons = sorted(geojson['features'], key=lambda feature: shape(feature['geometry']).area, reverse=True)\n",
    "\n",
    "# Apply transformations\n",
    "T = compute_timestamps(T)\n",
    "T = filter_duration(T)\n",
    "T = enrich_with_borough(T, sorted_polygons)\n",
    "T2 = clean_data(T)\n",
    "\n",
    "T.unpersist()\n",
    "T2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41fc285c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/workspace/local\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea6a70e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Reduce the number of partitions to one\n",
    "T2 = T2.coalesce(1)\n",
    "# Save the DataFrame as a CSV file in one single file\n",
    "T2.write.csv(\"./Taxi_Data/taxi_data_clean_enriched.csv\", header=True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff001797",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09bcc673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hack_license: string (nullable = true)\n",
      " |-- pickup_timestamp: integer (nullable = true)\n",
      " |-- dropoff_timestamp: integer (nullable = true)\n",
      " |-- Duration: double (nullable = true)\n",
      " |-- pickup_borough: string (nullable = true)\n",
      " |-- dropoff_borough: string (nullable = true)\n",
      "\n",
      "Number of Rows: 97167\n",
      "Total rows cleaned: 2606\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################################################################################\n",
    "# Verification\n",
    "\n",
    "spark.stop()\n",
    "spark = SparkSession.builder.appName('TaxiDataAnalysis').getOrCreate()\n",
    "\n",
    "# Load the taxi ride data\n",
    "taxi_data = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv('./Taxi_Data/taxi_data_clean_enriched.csv')\n",
    "\n",
    "# Display the schema and the first few rows to understand the data\n",
    "taxi_data.printSchema()\n",
    "\n",
    "print(\"Number of Rows:\", taxi_data.count())\n",
    "print(\"Total rows cleaned:\", old_row_count_2 - taxi_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "564c853b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All pickup and dropoff boroughs are in New York.\n"
     ]
    }
   ],
   "source": [
    "# boroughs verification\n",
    "df = taxi_data\n",
    "\n",
    "# Define a list of valid New York boroughs\n",
    "valid_boroughs = ['Manhattan', 'Brooklyn', 'Queens', 'Bronx', 'Staten Island']\n",
    "\n",
    "# Filter the DataFrame to include only rows where both pickup and dropoff boroughs are valid\n",
    "filtered_df = df.filter((col('pickup_borough').isin(valid_boroughs)) & (col('dropoff_borough').isin(valid_boroughs)))\n",
    "\n",
    "# Check if all rows passed the filter\n",
    "all_rows_are_in_ny = df.count() == filtered_df.count()\n",
    "\n",
    "# Display the result\n",
    "if all_rows_are_in_ny:\n",
    "    print(\"All pickup and dropoff boroughs are in New York.\")\n",
    "else:\n",
    "    print(\"Some pickup or dropoff boroughs are not in New York.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d2c0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97214c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################################################################################################\n",
    "# Query 1 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "783563d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+--------------+---------+---------------+------------------+\n",
      "|        hack_license|dropoff_borough|rides_duration|idle_time|total_work_time|       utilization|\n",
      "+--------------------+---------------+--------------+---------+---------------+------------------+\n",
      "|02856AFC22881ABCA...|      Manhattan|        1320.0|     2640|         3960.0| 33.33333333333333|\n",
      "|03A2D28F831C5C3E5...|      Manhattan|        3600.0|    12480|        16080.0|22.388059701492537|\n",
      "|03A2D28F831C5C3E5...|         Queens|        3000.0|     6540|         9540.0|31.446540880503143|\n",
      "|0FBF11956EE14B253...|      Manhattan|        4980.0|    20100|        25080.0| 19.85645933014354|\n",
      "|0FBF11956EE14B253...|         Queens|        1320.0|     5460|         6780.0|19.469026548672566|\n",
      "|13CD9D132F9DFE9BD...|      Manhattan|         300.0|      300|          600.0|              50.0|\n",
      "|13CD9D132F9DFE9BD...|       Brooklyn|        1320.0|     2640|         3960.0| 33.33333333333333|\n",
      "|28A7C858D9231A3EC...|         Queens|        1080.0|     1920|         3000.0|              36.0|\n",
      "|2E18539FA05E802C2...|      Manhattan|        2460.0|     1980|         4440.0|  55.4054054054054|\n",
      "|2E18539FA05E802C2...|         Queens|        1080.0|      540|         1620.0| 66.66666666666666|\n",
      "|31195E1D3AA1EC26D...|       Brooklyn|        1320.0|     2100|         3420.0| 38.59649122807017|\n",
      "|31195E1D3AA1EC26D...|      Manhattan|        6480.0|     7440|        13920.0| 46.55172413793103|\n",
      "|31195E1D3AA1EC26D...|         Queens|        2160.0|      960|         3120.0| 69.23076923076923|\n",
      "|3183016714F5E253E...|      Manhattan|        4140.0|     4680|         8820.0| 46.93877551020408|\n",
      "|3183016714F5E253E...|         Queens|        4440.0|     8160|        12600.0| 35.23809523809524|\n",
      "|3183016714F5E253E...|       Brooklyn|        1860.0|     6420|         8280.0|22.463768115942027|\n",
      "|428AE5AF18511D16B...|      Manhattan|       14100.0|    19800|        33900.0|  41.5929203539823|\n",
      "|428AE5AF18511D16B...|         Queens|        2100.0|     1140|         3240.0| 64.81481481481481|\n",
      "|42D2B75CA34A867A4...|         Queens|         840.0|     7740|         8580.0|  9.79020979020979|\n",
      "|42D2B75CA34A867A4...|      Manhattan|         840.0|     1140|         1980.0| 42.42424242424242|\n",
      "+--------------------+---------------+--------------+---------+---------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# 1. Sorting and Time Difference Calculation\n",
    "# ==========================\n",
    "\n",
    "# Sort the DataFrame by driver and pickup_timestamp for accurate time difference calculation\n",
    "sorted_df = taxiData.orderBy(\"hack_license\", \"pickup_timestamp\")\n",
    "\n",
    "# Using a window function to calculate the time difference in seconds between the current ride's pickup \n",
    "# and the previous ride's dropoff for the same driver\n",
    "window_spec = Window.partitionBy(\"hack_license\").orderBy(\"pickup_timestamp\")\n",
    "df_with_time_diff = sorted_df.withColumn(\"time_diff_seconds\", \n",
    "                                         (F.col(\"pickup_timestamp\") - F.lag(\"dropoff_timestamp\").over(window_spec)))\n",
    "\n",
    "# ==========================\n",
    "# 2. Filtering Idle Times\n",
    "# ==========================\n",
    "\n",
    "# Filter out rows where the idle time (time_diff_seconds) is greater than 0 seconds and less than 4 hours (14400 seconds)\n",
    "df_filtered_idle = df_with_time_diff.filter((F.col(\"time_diff_seconds\") > 0) & (F.col(\"time_diff_seconds\") < 14400))\n",
    "\n",
    "# Convert the \"Duration\" column from minutes to seconds for uniformity\n",
    "df_filtered_idle = df_filtered_idle.withColumn(\"Duration_seconds\", F.col(\"Duration\") * 60)\n",
    "\n",
    "# ==========================\n",
    "# 3. Aggregation and Utilization Calculation\n",
    "# ==========================\n",
    "\n",
    "# Group by driver (hack_license) and destination borough (dropoff_borough)\n",
    "# Sum the ride duration (in seconds) and idle time (in seconds) for each group\n",
    "result = df_filtered_idle.groupBy(\"hack_license\", \"dropoff_borough\").agg(\n",
    "    F.sum(\"Duration_seconds\").alias(\"rides_duration\"),\n",
    "    F.sum(\"time_diff_seconds\").alias(\"idle_time\")\n",
    ")\n",
    "\n",
    "# Calculate the total work time for each driver in each borough as the sum of ride duration and idle time\n",
    "result = result.withColumn(\"total_work_time\", F.col(\"idle_time\") + F.col(\"rides_duration\"))\n",
    "\n",
    "# Calculate the utilization, which represents the percentage of time a taxi is occupied with a passenger \n",
    "# compared to the total work time\n",
    "result = result.withColumn(\"utilization\", (F.col(\"rides_duration\") / F.col(\"total_work_time\")) * 100)\n",
    "\n",
    "# Display the final result\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8425477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################################################################################################\n",
    "# Query 2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfcd78c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------------+\n",
      "|dropoff_borough|avg_time_to_find_fare|\n",
      "+---------------+---------------------+\n",
      "|         Queens|   1394.4181646168402|\n",
      "|       Brooklyn|   1175.2196531791908|\n",
      "|  Staten Island|                320.0|\n",
      "|      Manhattan|    893.0988468064967|\n",
      "|          Bronx|   1173.6315789473683|\n",
      "+---------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# 1. Time Difference Calculation\n",
    "# ==========================\n",
    "\n",
    "# Using a window function to calculate the time difference in seconds between the current ride's pickup \n",
    "# and the previous ride's dropoff for the same driver\n",
    "window_spec = Window.partitionBy(\"hack_license\").orderBy(\"pickup_timestamp\")\n",
    "time_diff = (F.col(\"pickup_timestamp\").cast(\"long\") - F.lag(\"dropoff_timestamp\").over(window_spec)).alias(\"time_diff\")\n",
    "\n",
    "# Add the calculated time difference to the DataFrame. If the time difference is null (e.g., for the first ride of a driver), \n",
    "# set it to 0.\n",
    "enriched_data = taxiData.withColumn(\"time_diff\", F.when(F.isnull(time_diff), 0).otherwise(time_diff))\n",
    "\n",
    "# ==========================\n",
    "# 2. Filtering Data\n",
    "# ==========================\n",
    "\n",
    "# Filter out rides where the time difference between the current ride's pickup and the previous ride's dropoff \n",
    "# is more than 4 hours (14,400 seconds)\n",
    "filtered_data = enriched_data.filter(F.col(\"time_diff\") <= 14400)\n",
    "\n",
    "# ==========================\n",
    "# 3. Aggregation\n",
    "# ==========================\n",
    "\n",
    "# Group the data by the destination borough (dropoff_borough) and calculate the average time difference \n",
    "# (representing the average time taken by a taxi to find its next fare after dropping off a passenger in that borough)\n",
    "result = filtered_data.groupBy(\"dropoff_borough\").agg(F.avg(\"time_diff\").alias(\"avg_time_to_find_fare\"))\n",
    "\n",
    "# Display the final result\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31d63768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------+-------------+------------------+-----+\n",
      "|        hack_license|Queens|Brooklyn|Staten Island|         Manhattan|Bronx|\n",
      "+--------------------+------+--------+-------------+------------------+-----+\n",
      "|02856AFC22881ABCA...|   0.0|     0.0|          0.0|             880.0|  0.0|\n",
      "|03A2D28F831C5C3E5...|3270.0|     0.0|          0.0|            2080.0|  0.0|\n",
      "|069B5562096AF7684...|   0.0|     0.0|          0.0|               0.0|  0.0|\n",
      "|0FBF11956EE14B253...|5460.0|     0.0|          0.0|2233.3333333333335|  0.0|\n",
      "|130328475AD7427AF...|   0.0|     0.0|          0.0|               0.0|  0.0|\n",
      "|138B0A7B7D3B898E4...|   0.0|     0.0|          0.0|               0.0|  0.0|\n",
      "|13CD9D132F9DFE9BD...|   0.0|  2640.0|          0.0|             150.0|  0.0|\n",
      "|28A7C858D9231A3EC...|1920.0|     0.0|          0.0|               0.0|  0.0|\n",
      "|2E18539FA05E802C2...| 540.0|     0.0|          0.0|             495.0|  0.0|\n",
      "|31195E1D3AA1EC26D...| 960.0|  1050.0|          0.0| 1062.857142857143|  0.0|\n",
      "|3183016714F5E253E...|2720.0|  6420.0|          0.0| 668.5714285714286|  0.0|\n",
      "|428AE5AF18511D16B...|1140.0|     0.0|          0.0| 707.1428571428571|  0.0|\n",
      "|42D2B75CA34A867A4...|3870.0|     0.0|          0.0|             570.0|  0.0|\n",
      "|44D39A75B5BADD81E...|   0.0|     0.0|          0.0|             312.0|  0.0|\n",
      "|49EE1E8ECFA1C6D35...|   0.0|  6420.0|          0.0|             420.0|  0.0|\n",
      "|4B6EFCBC110DB539E...|   0.0|     0.0|          0.0|               0.0|  0.0|\n",
      "|588A002C06DD0B24F...|   0.0|     0.0|          0.0|           1001.25|  0.0|\n",
      "|669FA40A7222D4DC2...|   0.0|     0.0|          0.0|            1147.5|  0.0|\n",
      "|69996930170E51265...|   0.0|     0.0|          0.0| 745.2631578947369|  0.0|\n",
      "|74A3ADB671DEC83CC...| 180.0|     0.0|          0.0|             865.0|  0.0|\n",
      "+--------------------+------+--------+-------------+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Number of Rows: 9844\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Bonus : Pivot and Aggregation\n",
    "# ==========================\n",
    "\n",
    "# Pivot the data based on the 'dropoff_borough' column to get the average time difference for each borough.\n",
    "# The pivot function will create a separate column for each borough.\n",
    "pivoted_data = filtered_data.groupBy(\"hack_license\").pivot(\"dropoff_borough\", [\"Queens\", \"Brooklyn\", \"Staten Island\", \"Manhattan\", \"Bronx\"]).avg(\"time_diff\")\n",
    "\n",
    "# Fill any null values with 0 (indicating no rides to that borough for the driver)\n",
    "pivoted_data = pivoted_data.fillna(0)\n",
    "\n",
    "# Display the final result\n",
    "pivoted_data.show()\n",
    "\n",
    "# Print the number of rows in the final DataFrame\n",
    "row_count = pivoted_data.count()\n",
    "print(\"Number of Rows:\", row_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0086d21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################################################################################################\n",
    "# Query 3 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59100cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trips that started and ended in the same borough: 85773\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# 1. Filtering Data\n",
    "# ==========================\n",
    "\n",
    "# Filter out trips where the pickup and dropoff boroughs are the same.\n",
    "# This helps in identifying trips that started and ended within the same borough.\n",
    "same_borough_trips = taxiData.filter(F.col(\"pickup_borough\") == F.col(\"dropoff_borough\"))\n",
    "\n",
    "# ==========================\n",
    "# 2. Counting Trips\n",
    "# ==========================\n",
    "\n",
    "# Count the number of trips that started and ended in the same borough.\n",
    "# This gives an insight into the number of intra-borough trips.\n",
    "num_same_borough_trips = same_borough_trips.count()\n",
    "\n",
    "# Display the result\n",
    "print(\"Number of trips that started and ended in the same borough:\", num_same_borough_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76f9505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################################################################################################\n",
    "# Query 4 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f03caf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trips that started in one borough and ended in another: 11394\n",
      "Number of trips using alternative method: 11394\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# 1. Filtering Data\n",
    "# ==========================\n",
    "\n",
    "# Filter out trips where the pickup and dropoff boroughs are different.\n",
    "# This helps in identifying trips that started in one borough and ended in another.\n",
    "inter_borough_trips = taxiData.filter(F.col(\"pickup_borough\") != F.col(\"dropoff_borough\"))\n",
    "\n",
    "# ==========================\n",
    "# 2. Counting Trips\n",
    "# ==========================\n",
    "\n",
    "# Count the number of trips that started in one borough and ended in another.\n",
    "# This gives an insight into the number of inter-borough trips.\n",
    "num_inter_borough_trips = inter_borough_trips.count()\n",
    "\n",
    "# Display the result\n",
    "print(\"Number of trips that started in one borough and ended in another:\", num_inter_borough_trips)\n",
    "\n",
    "# ==========================\n",
    "# 3. Alternative Method\n",
    "# ==========================\n",
    "\n",
    "# An alternative method to calculate the number of inter-borough trips is to subtract the number of \n",
    "# intra-borough trips (same borough trips) from the total number of trips.\n",
    "total_trips = taxiData.count()\n",
    "num_inter_borough_trips_alt = total_trips - num_same_borough_trips\n",
    "\n",
    "# Display the result from the alternative method\n",
    "print(\"Number of trips using alternative method:\", num_inter_borough_trips_alt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
